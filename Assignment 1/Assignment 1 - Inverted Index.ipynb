{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Retrieval (CSD312)\n",
    " Assignment 1 - Inverted Index (January 16th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Write the program to construct an Inverted Index for a given document collection comprising of at least 50 documents with a total vocabulary size of at least 1000 words.  The program should take the input as boolean search queries using AND, OR and NOT operators and return the list of the documents satisfying the query need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "midsummer_night_dream = open(\"shakespeare/dream.txt\", \"r\").read().splitlines()\n",
    "hamlet = open(\"shakespeare/hamlet.txt\", \"r\").read().splitlines()\n",
    "macbeth = open(\"shakespeare/macbeth.txt\", \"r\").read().splitlines()\n",
    "othello = open(\"shakespeare/othello.txt\", \"r\").read().splitlines()\n",
    "r_and_j = open(\"shakespeare/r_and_j.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(parent_document, num):\n",
    "    a = []\n",
    "    parent_document = list(parent_document)\n",
    "    for i in range (num):\n",
    "        a.append([])\n",
    "        \n",
    "    for i in range(len(parent_document)):\n",
    "        a[i%num].append(parent_document[i])\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "midsummer_night_dream = create_documents(midsummer_night_dream, 10)\n",
    "hamlet = create_documents(hamlet, 10)\n",
    "macbeth = create_documents(macbeth, 10)\n",
    "othello = create_documents(othello, 10)\n",
    "r_and_j = create_documents(r_and_j, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_documents = [\"midsummer_night_dream\", \"hamlet\", \"macbeth\", \"r_and_j\", \"othello\"]\n",
    "documents = [\"midsummer_night_dream_0\", \"midsummer_night_dream_1\", \"midsummer_night_dream_2\", \n",
    "             \"midsummer_night_dream_3\", \"midsummer_night_dream_4\", \"midsummer_night_dream_5\", \n",
    "             \"midsummer_night_dream_6\", \"midsummer_night_dream_7\", \"midsummer_night_dream_8\", \n",
    "             \"midsummer_night_dream_9\", \"hamlet_0\", \"hamlet_1\", \"hamlet_2\", \"hamlet_3\", \"hamlet_4\", \n",
    "             \"hamlet_5\", \"hamlet_6\", \"hamlet_7\", \"hamlet_8\", \"hamlet_9\", \"macbeth_0\", \"macbeth_1\", \n",
    "             \"macbeth_2\", \"macbeth_3\", \"macbeth_4\", \"macbeth_5\", \"macbeth_6\", \"macbeth_7\", \"macbeth_8\", \n",
    "             \"macbeth_9\", \"r_and_j_0\", \"r_and_j_1\", \"r_and_j_2\", \"r_and_j_3\", \"r_and_j_4\", \"r_and_j_5\", \n",
    "             \"r_and_j_6\", \"r_and_j_7\", \"r_and_j_8\", \"r_and_j_9\", \"othello_0\", \"othello_1\", \"othello_2\", \n",
    "             \"othello_3\", \"othello_4\", \"othello_5\", \"othello_6\", \"othello_7\", \"othello_8\", \"othello_9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "midsummer_night_dream_0 = midsummer_night_dream[0]\n",
    "midsummer_night_dream_1 = midsummer_night_dream[1]\n",
    "midsummer_night_dream_2 = midsummer_night_dream[2]\n",
    "midsummer_night_dream_3 = midsummer_night_dream[3]\n",
    "midsummer_night_dream_4 = midsummer_night_dream[4]\n",
    "midsummer_night_dream_5 = midsummer_night_dream[5]\n",
    "midsummer_night_dream_6 = midsummer_night_dream[6]\n",
    "midsummer_night_dream_7 = midsummer_night_dream[7]\n",
    "midsummer_night_dream_8 = midsummer_night_dream[8]\n",
    "midsummer_night_dream_9 = midsummer_night_dream[9]\n",
    "hamlet_0 = hamlet[0]\n",
    "hamlet_1 = hamlet[1]\n",
    "hamlet_2 = hamlet[2]\n",
    "hamlet_3 = hamlet[3]\n",
    "hamlet_4 = hamlet[4]\n",
    "hamlet_5 = hamlet[5]\n",
    "hamlet_6 = hamlet[6]\n",
    "hamlet_7 = hamlet[7]\n",
    "hamlet_8 = hamlet[8]\n",
    "hamlet_9 = hamlet[9]\n",
    "macbeth_0 = macbeth[0]\n",
    "macbeth_1 = macbeth[1]\n",
    "macbeth_2 = macbeth[2]\n",
    "macbeth_3 = macbeth[3]\n",
    "macbeth_4 = macbeth[4]\n",
    "macbeth_5 = macbeth[5]\n",
    "macbeth_6 = macbeth[6]\n",
    "macbeth_7 = macbeth[7]\n",
    "macbeth_8 = macbeth[8]\n",
    "macbeth_9 = macbeth[9]\n",
    "r_and_j_0 = r_and_j[0]\n",
    "r_and_j_1 = r_and_j[1]\n",
    "r_and_j_2 = r_and_j[2]\n",
    "r_and_j_3 = r_and_j[3]\n",
    "r_and_j_4 = r_and_j[4]\n",
    "r_and_j_5 = r_and_j[5]\n",
    "r_and_j_6 = r_and_j[6]\n",
    "r_and_j_7 = r_and_j[7]\n",
    "r_and_j_8 = r_and_j[8]\n",
    "r_and_j_9 = r_and_j[9]\n",
    "othello_0 = othello[0]\n",
    "othello_1 = othello[1]\n",
    "othello_2 = othello[2]\n",
    "othello_3 = othello[3]\n",
    "othello_4 = othello[4]\n",
    "othello_5 = othello[5]\n",
    "othello_6 = othello[6]\n",
    "othello_7 = othello[7]\n",
    "othello_8 = othello[8]\n",
    "othello_9 = othello[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning documents and tokenizing into words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html\n",
    "import re\n",
    "\n",
    "def removeNonAscii(s): \n",
    "    return \"\".join(i for i in s if(ord(i)==32 or (ord(i)<128 and ord(i)>65)))\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" \", string)\n",
    "    string = re.sub(r\"\\(\", \" \", string)\n",
    "    string = re.sub(r\"\\)\", \" \", string)\n",
    "    string = re.sub(r\"\\?\", \" \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"what's\", \"what is \", string)\n",
    "    string = string.replace('(ap)', '')\n",
    "    string = re.sub(r\"\\'s\", \" is \", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have \", string)\n",
    "    string = re.sub(r\"can't\", \"cannot \", string)\n",
    "    string = re.sub(r\"n't\", \" not \", string)\n",
    "    string = re.sub(r\"i'm\", \"i am \", string)\n",
    "    string = re.sub(r\"\\'re\", \" are \", string)\n",
    "    string = re.sub(r\"\\'d\", \" would \", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will \", string)\n",
    "    string = removeNonAscii(string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning documents\n",
    "\n",
    "def clean_document(document):\n",
    "    return [clean_str(sentence) for sentence in document if(sentence != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting sentences into words\n",
    "\n",
    "def tokenize(document):\n",
    "    return [sentence.split() for sentence in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate words and creating one list from list of lists\n",
    "\n",
    "def remove_duplicates(document):\n",
    "    return set([item for sublist in document for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    globals()[document] = clean_document(globals()[document])\n",
    "    globals()[document] = tokenize(globals()[document])\n",
    "    globals()[document] = remove_duplicates(globals()[document])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {\"midsummer_night_dream_0\" : 0,\n",
    "\"midsummer_night_dream_1\" : 1,\n",
    "\"midsummer_night_dream_2\" : 2,\n",
    "\"midsummer_night_dream_3\" : 3,\n",
    "\"midsummer_night_dream_4\" : 4,\n",
    "\"midsummer_night_dream_5\" : 5,\n",
    "\"midsummer_night_dream_6\" : 6,\n",
    "\"midsummer_night_dream_7\" : 7,\n",
    "\"midsummer_night_dream_8\" : 8,\n",
    "\"midsummer_night_dream_9\" : 9,\n",
    "\"hamlet_0\" : 10,\n",
    "\"hamlet_1\" : 11,\n",
    "\"hamlet_2\" : 12,\n",
    "\"hamlet_3\" : 13,\n",
    "\"hamlet_4\" : 14,\n",
    "\"hamlet_5\" : 15,\n",
    "\"hamlet_6\" : 16,\n",
    "\"hamlet_7\" : 17,\n",
    "\"hamlet_8\" : 18,\n",
    "\"hamlet_9\" : 19,\n",
    "\"macbeth_0\" : 20,\n",
    "\"macbeth_1\" : 21,\n",
    "\"macbeth_2\" : 22,\n",
    "\"macbeth_3\" : 23,\n",
    "\"macbeth_4\" : 24,\n",
    "\"macbeth_5\" : 25,\n",
    "\"macbeth_6\" : 26,\n",
    "\"macbeth_7\" : 27,\n",
    "\"macbeth_8\" : 28,\n",
    "\"macbeth_9\" : 29,\n",
    "\"r_and_j_0\" : 30,\n",
    "\"r_and_j_1\" : 31,\n",
    "\"r_and_j_2\" : 32,\n",
    "\"r_and_j_3\" : 33,\n",
    "\"r_and_j_4\" : 34,\n",
    "\"r_and_j_5\" : 35,\n",
    "\"r_and_j_6\" : 36,\n",
    "\"r_and_j_7\" : 37,\n",
    "\"r_and_j_8\" : 38,\n",
    "\"r_and_j_9\" : 39,\n",
    "\"othello_0\" : 40,\n",
    "\"othello_1\" : 41,\n",
    "\"othello_2\" : 42,\n",
    "\"othello_3\" : 43,\n",
    "\"othello_4\" : 44,\n",
    "\"othello_5\" : 45,\n",
    "\"othello_6\" : 46,\n",
    "\"othello_7\" : 47,\n",
    "\"othello_8\" : 48,\n",
    "\"othello_9\" : 49}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# for document in documents:\n",
    "#     for i in range(10):\n",
    "#         print(\"\\\"\"+document+\"_\"+str(i)+\"\\\"\"+\",\", end=\" \")\n",
    "#         k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words in midsummer_night_dream_0: 768\n",
      "No of words in midsummer_night_dream_1: 756\n",
      "No of words in midsummer_night_dream_2: 753\n",
      "No of words in midsummer_night_dream_3: 775\n",
      "No of words in midsummer_night_dream_4: 788\n",
      "No of words in midsummer_night_dream_5: 804\n",
      "No of words in midsummer_night_dream_6: 757\n",
      "No of words in midsummer_night_dream_7: 808\n",
      "No of words in midsummer_night_dream_8: 805\n",
      "No of words in midsummer_night_dream_9: 750\n",
      "No of words in hamlet_0: 1139\n",
      "No of words in hamlet_1: 1192\n",
      "No of words in hamlet_2: 1113\n",
      "No of words in hamlet_3: 1156\n",
      "No of words in hamlet_4: 1158\n",
      "No of words in hamlet_5: 1140\n",
      "No of words in hamlet_6: 1119\n",
      "No of words in hamlet_7: 1142\n",
      "No of words in hamlet_8: 1128\n",
      "No of words in hamlet_9: 1139\n",
      "No of words in macbeth_0: 836\n",
      "No of words in macbeth_1: 913\n",
      "No of words in macbeth_2: 881\n",
      "No of words in macbeth_3: 844\n",
      "No of words in macbeth_4: 872\n",
      "No of words in macbeth_5: 887\n",
      "No of words in macbeth_6: 875\n",
      "No of words in macbeth_7: 879\n",
      "No of words in macbeth_8: 852\n",
      "No of words in macbeth_9: 879\n",
      "No of words in r_and_j_0: 989\n",
      "No of words in r_and_j_1: 1003\n",
      "No of words in r_and_j_2: 987\n",
      "No of words in r_and_j_3: 986\n",
      "No of words in r_and_j_4: 957\n",
      "No of words in r_and_j_5: 941\n",
      "No of words in r_and_j_6: 1006\n",
      "No of words in r_and_j_7: 998\n",
      "No of words in r_and_j_8: 1003\n",
      "No of words in r_and_j_9: 959\n",
      "No of words in othello_0: 1028\n",
      "No of words in othello_1: 1047\n",
      "No of words in othello_2: 1011\n",
      "No of words in othello_3: 1002\n",
      "No of words in othello_4: 1017\n",
      "No of words in othello_5: 1063\n",
      "No of words in othello_6: 1025\n",
      "No of words in othello_7: 1011\n",
      "No of words in othello_8: 1019\n",
      "No of words in othello_9: 1026\n"
     ]
    }
   ],
   "source": [
    "for document in documents.keys():\n",
    "    print(\"No of words in \"+document+\": \"+str(len(globals()[document])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for document in documents.keys():\n",
    "    words = words + list(globals()[document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of words in documents: 47986\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no. of words in documents: \"+ str(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sorted(words):\n",
    "    inverted_index[word] = [documents[document] for document in documents.keys() if word in globals()[document]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing the document count in posting list\n",
    "for key, value in inverted_index.items():\n",
    "    value = sorted(value)\n",
    "    value.insert(0,len(value))\n",
    "    inverted_index[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: First element in the postings list is the document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a',\n",
       "  [50,\n",
       "   0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49]),\n",
       " ('abbey', [1, 30]),\n",
       " ('abbreviations', [3, 13, 24, 46]),\n",
       " ('abed', [2, 31, 39]),\n",
       " ('abhominably', [1, 17])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (word, [len of postings, postings])\n",
    "# ('abate', [2, 1, 4])\n",
    "\n",
    "list(inverted_index.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Boolean Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use format word1 [and/or/not] word2\n",
    "\n",
    "query = \"moon and sun and house and great and man and woman and water\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moon and sun and house and great and man and woman and water\n",
      "['moon', 'sun', 'house', 'great', 'man', 'woman', 'water']\n",
      "[13, 18, 32, 36, 49, 27, 16]\n"
     ]
    }
   ],
   "source": [
    "query_tokenized = query.split()\n",
    "query_words = query_tokenized[::2]\n",
    "query_words_weights = [inverted_index[word][0] for word in query_words]\n",
    "\n",
    "\n",
    "print(query)\n",
    "print(query_words)\n",
    "print(query_words_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = [word for _,word in sorted(zip(query_words_weights,query_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_words_postings = [inverted_index[word][1:] for word in query_words]\n",
    "\n",
    "sorted_words_postings = [inverted_index[word][1:] for word in sorted_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    # Use of hybrid method \n",
    "    temp = set(lst2) \n",
    "    lst3 = [value for value in lst1 if value in temp] \n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.00028324999948381446\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "result_sorted = reduce((lambda x, y: intersection(x,y)), sorted_words_postings)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.0002149600004486274\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "result_unsorted = reduce((lambda x, y: intersection(x,y)), query_words_postings)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
